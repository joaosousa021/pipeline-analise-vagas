# üß† Pipeline de ETL com NLP para An√°lise de Vagas de Dados

![Status](https://img.shields.io/badge/status-conclu√≠do-brightgreen)
![Python](https://img.shields.io/badge/python-3.9%2B-blue)
![spaCy](https://img.shields.io/badge/NLP-spaCy-blueviolet)

## üéØ Objetivo

Este projeto implementa um pipeline de dados **ETL (Extract, Transform, Load)** completo que utiliza t√©cnicas de **Intelig√™ncia Artificial** para analisar o mercado de trabalho de Engenharia de Dados. O objetivo √© converter dados textuais n√£o estruturados, extra√≠dos da web, em insights estruturados e acion√°veis sobre as compet√™ncias t√©cnicas mais demandadas pelas empresas.

## ‚ú® Resultado Final

O pipeline processa milhares de palavras das descri√ß√µes das vagas e, aplicando um modelo de NLP, gera uma visualiza√ß√£o clara das tecnologias e habilidades mais requisitadas, oferecendo um panorama estrat√©gico das tend√™ncias do setor.

![Gr√°fico de Top Skills](top_skills.png)

## üèõÔ∏è Arquitetura do Pipeline

O projeto segue a cl√°ssica arquitetura ETL, onde a etapa de Transforma√ß√£o √© enriquecida com um componente de Intelig√™ncia Artificial.

1.  **`Extra√ß√£o (Extract)`**

    - Um script de web scraping √©tico (`01_extracao.py`) navega pelo portal **Programathor** para coletar dados p√∫blicos de vagas (t√≠tulo, empresa, local e a descri√ß√£o completa), utilizando pausas e headers para n√£o sobrecarregar o servidor.
    - **Ferramentas:** `Requests`, `BeautifulSoup4`.

2.  **`Transforma√ß√£o (Transform)`**

    - Esta √© a fase central do projeto. O script `02_transformacao.py` recebe os dados brutos e realiza a limpeza e padroniza√ß√£o com Pandas.
    - Em seguida, aplicamos um modelo de **Processamento de Linguagem Natural (NLP)** com a biblioteca **`spaCy`** para realizar a **Extra√ß√£o de Entidades** a partir do texto n√£o estruturado das descri√ß√µes. Um `PhraseMatcher` otimizado √© utilizado para identificar e extrair um dicion√°rio customizado de _skills_, transformando texto livre em features quantific√°veis para an√°lise.
    - **Ferramentas:** `Pandas`, `spaCy` (NLP), `re` (Express√µes Regulares).

3.  **`Carga (Load)`**

    - Os dados limpos e enriquecidos com as features de IA s√£o carregados pelo script `03_carga.py` para um banco de dados relacional, garantindo o armazenamento persistente.
    - **Ferramentas:** `SQLite`.

4.  **`An√°lise e Visualiza√ß√£o (Analyze & Visualize)`**
    - Um notebook (`analise.ipynb`) conecta-se ao banco de dados para realizar consultas e agregar os dados, contando a frequ√™ncia de cada habilidade extra√≠da pelo modelo de NLP.
    - O resultado da an√°lise √© exibido em um gr√°fico de barras, facilitando a interpreta√ß√£o dos insights.
    - **Ferramentas:** `Jupyter Lab`, `Matplotlib`, `Pandas`.

## üõ†Ô∏è Tecnologias e Habilidades

- **Engenharia de Dados:** Desenvolvimento de Pipelines ETL, Web Scraping, Limpeza e Estrutura√ß√£o de Dados.
- **Intelig√™ncia Artificial:** Processamento de Linguagem Natural (NLP) e Extra√ß√£o de Entidades com **`spaCy`**.
- **Linguagem:** Python.
- **Bibliotecas:** Pandas, Matplotlib, Requests, BeautifulSoup4, spaCy.
- **Banco de Dados:** SQLite.
- **Ferramentas:** Git, GitHub, Ambientes Virtuais (`venv`), Jupyter Lab.

## üöÄ Como Executar o Projeto

Siga os passos abaixo para executar o pipeline em seu ambiente local.

**Pr√©-requisitos:**

- Python 3.9+
- Git

**Passos:**

1.  **Clone o reposit√≥rio:**

    ```bash
    git clone [https://github.com/joaosousa021/pipeline-analise-vagas.git](https://github.com/joaosousa021/pipeline-analise-vagas.git)
    cd pipeline-analise-vagas
    ```

2.  **Crie e ative o ambiente virtual:**

    ```bash
    python -m venv venv
    # No Windows:
    .\venv\Scripts\activate
    # No Mac/Linux:
    source venv/bin/activate
    ```

3.  **Instale as depend√™ncias (incluindo o modelo spaCy):**

    ```bash
    pip install -r requirements.txt
    python -m spacy download pt_core_news_sm
    ```

4.  **Execute o pipeline ETL completo:**

    ```bash
    python 01_extracao.py
    python 02_transformacao.py
    python 03_carga.py
    ```

5.  **Visualize a an√°lise:**
    - Inicie o Jupyter Lab:
      ```bash
      python -m jupyter lab
      ```
    - No seu navegador, abra o arquivo `analise.ipynb`.
    - Para executar cada passo da an√°lise, selecione uma c√©lula e pressione **`Shift + Enter`**. A √∫ltima c√©lula ir√° gerar o gr√°fico.
